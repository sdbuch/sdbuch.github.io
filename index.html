<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>Sam D. Buchanan</title>
  <meta name="description" content="Homepage of Sam D. Buchanan, researcher in the mathematics of data science and deep learning.">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://sdbuchanan.com/">
  
  
  <link rel="alternate" type="application/rss+xml" title="Sam D. Buchanan" href="http://sdbuchanan.com/feed.xml">

  
<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- MathJax -->
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>



<link
  href="https://fonts.googleapis.com"
  rel="preconnect"
  />
<link
  href="https://fonts.gstatic.com"
  rel="preconnect"
  crossorigin="anonymous"
  />
<script
  src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"
  type="text/javascript"
  ></script>
<script type="text/javascript">
  WebFont.load({
    google: {
      families: [
        "Lato:300,300italic,400,400italic,700,700italic",
        "Open Sans:300,300italic,400,400italic,700,700italic",
      ],
    },
  });
</script>


  
  <meta property="og:title" content="Sam D. Buchanan">
  <meta property="og:site_name" content="Sam D. Buchanan">
  <meta property="og:url" content="http://sdbuchanan.com/">
  <meta property="og:description" content="Homepage of Sam D. Buchanan, researcher in the mathematics of data science and deep learning.">
  
  
    <meta property="og:image" content="/assets/sam-2023.jpeg">
  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:title" content="Sam D. Buchanan">
  <meta name="twitter:description" content="Homepage of Sam D. Buchanan, researcher in the mathematics of data science and deep learning.">
  
  

  <link rel="dns-prefetch" href="https://fonts.gstatic.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,700;1,400&amp;display=swap" rel="stylesheet">

  

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Sam D. Buchanan</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/">Home</a>
      
        
        <a class="page-link" href="/publications/">Publications</a>
      
        
        <a class="page-link" href="/misc/">Misc.</a>
      
        
        <a class="page-link" href="/assets/cv.pdf">CV</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home">

  <div id="contact-container">
  <div class="pic">
    <img src="/assets/sam-2023.jpeg" alt="Photo of Sam
    Buchanan" style="border-radius: 15px;" />
  </div>
  <div class="info">
    <h3>Sam Buchanan</h3>
    <p>
      Research Assistant Professor
      <br />
      <a href="https://ttic.edu/">
        Toyota Technological Institute at Chicago
      </a>
      <a id="email-small" href="mailto:sam@ttic.edu">sam@ttic.edu</a> 
    </p>
    <p id="address"><a href="mailto:sam@ttic.edu">sam@ttic.edu</a> <br />
    6045 South Kenwood Ave, 411 <br />
    Chicago, IL 60637</p>
  </div>
</div>

<p>I am a Research Assistant Professor at <a href="https://ttic.edu">TTIC</a>. I completed
my Ph.D. in Electrical Engineering at <a href="https://ee.columbia.edu">Columbia
University</a> in 2022, working with <a href="http://www.columbia.edu/~jw2966/">John
Wright</a>, and my B.S. in Electrical
Engineering at the <a href="https://eecs.ku.edu">University of Kansas</a>.</p>

<p>I study the mathematics of representation learning from the
perspective of signals and data. I’m interested in questions that span theory
and practice — What structural properties of modern data play a role in the
success or failure of deep learning? How can we design better deep
architectures by exploiting these structures? I’m especially interested in
applications to visual data.</p>

<h2 id="upcoming-events">Upcoming Events</h2>

<ul>
  <li>
    <p><strong>ICLR 2024</strong>: Presenting two posters in Vienna: <em>Learned Proximal Networks</em>
(Friday, May 10, a.m. session; <a href="https://zhenghanfang.github.io/learned-proximal-networks/">project
page</a>, <a href="https://iclr.cc/virtual/2024/poster/17978">ICLR
page</a>) and <em>CRATE-MAE</em> (Thursday,
May 9, a.m. session; <a href="https://ma-lab-berkeley.github.io/CRATE/">project
page</a>, <a href="https://iclr.cc/virtual/2024/poster/18688">ICLR
page</a>). Come say hi!</p>
  </li>
  <li>
    <p><strong>Tutorial:</strong> Giving a tutorial lecture on designing deep network
architectures to pursue low-dimensional structures in data and our recent
white-box transformers work at <a href="https://cvpr2024-tutorial-low-dim-models.github.io">CVPR
2024</a> in Seattle (Jun
2024).</p>
  </li>
  <li>
    <p><strong>Travel:</strong> Will be at BIRS Oaxaca for the
<a href="https://www.birs.ca/events/2024/5-day-workshops/24w5297">“Mathematics of Deep Learning” workshop</a> (Jun 2024).</p>
  </li>
</ul>

<h2 id="recent-highlights">Recent Highlights</h2>

<ul>
  <li>
    <p><strong>1st Conference on Parsimony and Learning:</strong> I co-organized the inaugural <a href="https://cpal.cc">Conference on
Parsimony and Learning (CPAL)</a>, which took place at the
University of Hong Kong from January 3–6, 2024. Thanks to all authors,
speakers, organizers, and especially to the local team at HKU, whose hard
work made the conference a success! Stay tuned for CPAL 2025. <em>(Jan 2024)</em></p>
  </li>
  <li>
    <p><strong>White-Box Deep Networks Tutorial:</strong> We delivered a tutorial on building white-box deep neural networks
at <a href="https://cmsworkshops.com/ICASSP2024/tutorials.php#tut25">ICASSP 2024</a> in
Seoul. <a href="https://drive.google.com/drive/folders/1j7wtXteUA0dNT8Bl5Q1hVGpBU9_QAzKu">Slides are
available</a>,
and video recordings will be published soon! <em>(Apr 2024)</em></p>
  </li>
</ul>

<h2 id="recent-updates">Recent Updates</h2>

<ul>
  <li>
    <p><strong>Publication:</strong> <a href="https://zhenghanfang.github.io/learned-proximal-networks/">Learned proximal networks</a>, a methodology for
parameterizing, learning, and evaluating expressive priors for data-driven inverse
problem solvers with convergence guarantees, will appear in ICLR 2024.
The camera-ready version of the manuscript can be found
<a href="https://openreview.net/forum?id=kNPcOaqC5r">here</a>. <em>(May 2024)</em></p>
  </li>
  <li>
    <p><strong>Publication:</strong> <a href="https://ma-lab-berkeley.github.io/CRATE/">CRATE-MAE</a> will
appear in ICLR 2024. At the heart of this work is a connection between
denoising and compression, which we use to derive a corresponding decoder
architecture for the “white-box” transformer CRATE encoder.
The camera-ready version of the manuscript can be found
<a href="https://openreview.net/forum?id=PvyOYleymy">here</a>. <em>(May 2024)</em>
<!-- This work is described in Section 3 of the [complete CRATE -->
<!-- paper](https://arxiv.org/abs/2311.13110). _(Jan 2024)_ --></p>
  </li>
  <li>
    <p><strong>Talk:</strong> Gave my annual Research at TTIC talk about <a href="https://brentyi.github.io/tilted">TILTED</a>! <a href="https://uchicago.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=db5b4c2a-96aa-4722-bb5f-b067015c0314">Here is the
video
recording</a>. <em>(Mar 2024)</em></p>
  </li>
  <li>
    <p><strong>Talk:</strong> Gave the <a href="https://redwood.berkeley.edu/seminars/sam-buchanan-feb-2024/">Redwood
Seminar</a>. <em>(Feb 2024)</em></p>
  </li>
  <li>
    <p><strong>Publication:</strong> We presented <a href="https://ma-lab-berkeley.github.io/CRATE/">CRATE</a> at <a href="https://neurips.cc/virtual/2023/poster/71567">NeurIPS
2023</a>, and as an oral in the
<a href="https://neurips.cc/virtual/2023/75163">XAI in Action</a> workshop. <em>(Dec 2023)</em></p>
  </li>
  <li>
    <p><strong>Preprint Release:</strong> The full version of <a href="http://arxiv.org/abs/2311.13110">the CRATE
story</a> is now on arXiv.
<a href="https://ma-lab-berkeley.github.io/CRATE/">CRATE</a> is a “white-box” (yet
scalable) transformer architecture where each layer is derived from the
principles of compression and sparsification of the input data distribution.
This white-box derivation leads CRATE’s representations to have surprising
<a href="https://arxiv.org/abs/2308.16271">emergent segmentation properties</a> in
vision applications without any complex self-supervised pretraining. <em>(Nov 2023)</em></p>
  </li>
  <li>
    <p><strong>Publication:</strong> We presented <a href="https://brentyi.github.io/tilted/">TILTED</a> at
ICCV 2023. TILTED improves visual quality, compactness, and interpretability
for hybrid neural field 3D representations by incorporating geometry into the
latent features. Find the full version <a href="https://arxiv.org/abs/2308.15461">on arXiv</a>. <em>(Oct 2023)</em></p>
  </li>
</ul>

<h2 id="past-updates"><a href="/past_updates">Past Updates</a></h2>


  

  <ul class="post-list">
    
  </ul>

  


</div>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      


<div id="icon-container">
  <div>
    <a href=mailto:sam@ttic.edu style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/gmail.svg" alt="Mail icon" />
    </a>
  </div>
  <div>
    <a href=https://scholar.google.com/citations?user=5WT38A0AAAAJ style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/scholar.svg" alt="Google Scholar icon" />
    </a>
  </div>

  <div>
    <a href=https://twitter.com/_sdbuchanan
       style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/twitter.svg" alt="Twitter icon" />
    </a>
  </div>

  <div>
    <a href=https://github.com/sdbuch
       style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/github.svg" alt="GitHub icon" />
    </a>
  </div>
</div>

    </p>

  </div>

</footer>


  </body>

  <!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
