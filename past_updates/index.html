<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Past Updates | Sam D. Buchanan</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Past Updates" />
<meta name="author" content="Sam Buchanan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Archived updates from the homepage." />
<meta property="og:description" content="Archived updates from the homepage." />
<link rel="canonical" href="http://sdbuchanan.com/past_updates/" />
<meta property="og:url" content="http://sdbuchanan.com/past_updates/" />
<meta property="og:site_name" content="Sam D. Buchanan" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Past Updates" />
<meta name="twitter:site" content="@_sdbuchanan" />
<meta name="twitter:creator" content="@Sam Buchanan" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Sam Buchanan"},"description":"Archived updates from the homepage.","headline":"Past Updates","url":"http://sdbuchanan.com/past_updates/"}</script>
<!-- End Jekyll SEO tag -->


  <link rel="stylesheet" href="/assets/main.css?v=1761172618">
  
  
  <link rel="alternate" type="application/rss+xml" title="Sam D. Buchanan" href="http://sdbuchanan.com/feed.xml">

  
<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- MathJax -->
<script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js"></script>

<!-- MathJax -->
<script type="text/javascript">
  const macros = {};

  // Generate BB letters
  for (let i = 65; i <= 90; i++) {
    const letter = String.fromCharCode(i);
    macros[`bb${letter}`] = `{\\mathbb{${letter}}}`;
  }

  // Generate script letters
  for (let i = 65; i <= 90; i++) {
    const letter = String.fromCharCode(i);
    macros[`c${letter}`] = `{\\mathscr{${letter}}}`;
  }

  // Generate calligraphic letters
  for (let i = 65; i <= 90; i++) {
    const letter = String.fromCharCode(i);
    macros[`s${letter}`] = `{\\mathcal{${letter}}}`;
  }

  // Generate vector uppercase letters
  for (let i = 65; i <= 90; i++) {
    const letter = String.fromCharCode(i);
    macros[`v${letter}`] = `{\\boldsymbol{${letter}}}`;
  }

  // Generate vector lowercase letters
  for (let i = 97; i <= 122; i++) {
    const letter = String.fromCharCode(i);
    macros[`v${letter}`] = `{\\boldsymbol{${letter}}}`;
  }

  // Add Greek letters
  const greekLetters = [
    'alpha', 'beta', 'gamma', 'delta', 'epsilon', 'varepsilon', 'zeta', 'eta',
    'theta', 'vartheta', 'iota', 'kappa', 'lambda', 'mu', 'nu', 'xi',
    'pi', 'varpi', 'rho', 'varrho', 'sigma', 'varsigma', 'tau', 'upsilon',
    'phi', 'varphi', 'chi', 'psi', 'omega', 'Gamma', 'Delta', 'Theta',
    'Lambda', 'Xi', 'Pi', 'Sigma', 'varSigma', 'Upsilon', 'Phi', 'Psi',
    'Omega', 'ell'
  ];
  greekLetters.forEach(letter => {
    macros[`v${letter}`] = `{\\boldsymbol{\\${letter}}}`;
  });

  // Add these to your macros object
  const additionalMacros = {
    // Basic macros
    "Beta": "{\\mathrm{B}}",
    "eps": "{\\epsilon}",
    "Diff": "{\\mathop{}\\!\\mathrm{D}}",
    "diff": "{\\mathop{}\\!\\mathrm{d}}",
    "Partial": ["{\\frac{\\partial #1}{\\partial #2}}", 2],
    "PartialN": ["{\\frac{\\partial^{#3} #1}{\\partial {#2}^{#3}}}", 3],
    "dPartial": ["{\\dfrac{\\partial #1}{\\partial #2}}", 2],
    "PPartial": ["{\\tfrac{\\partial}{\\partial #1}}", 1],
    "dac": "{\\left.\\frac{\\partial}{\\partial t}\\right|_{t=0}}",
    "half": "{\\tfrac{1}{2}}",
    "third": "{\\tfrac{1}{3}}",
    "fourth": "{\\tfrac{1}{4}}",
    "sixth": "{\\tfrac{1}{6}}", // Fixed typo (was 1/4)
    "eighth": "{\\tfrac{1}{8}}",

    // Accents and decorations
    "overbar": ["{\\mkern 1.5mu\\overline{\\mkern-1.5mu#1\\mkern-1.5mu}\\mkern 1.5mu}", 1],
    "underbar": ["{\\mkern 1.5mu\\underline{\\mkern-1.5mu#1\\mkern-1.5mu}\\mkern 1.5mu}", 1],
    "conj": ["{\\overbar{#1}}", 1],
    "wh": "{\\widehat}",
    "wt": "{\\widetilde}",
    "ol": ["{\\overbar{#1}}", 1],
    "kron": "{\\otimes}",
    "elwise": "{\\odot}", // Using \odot as circleddot is not standard
    "dsum": "{\\oplus}",
    "spcdot": "{\\,\\cdot\\,}",

    // Special symbols
    "iu": "{\\mathfrak{i}}",
    "given": [' \\, \\vert \\, ', 0],
    "llangle": ['\\langle\\!\\langle', 0],
    "rrangle": ['\\rangle\\!\\rangle', 0],

      // Analysis operators
    "Lip": "{\\mathrm{Lip}}",
    "mem": "{\\mathrm{mem}}",
    "softmax": "{\\operatorname{\\mathrm{softmax}}}",
    "equid": "{\\overset{d}{=}}",
    "xor": "{\\oplus}",
    "bigxor": "{\\bigoplus}",
    "minimize": ["{\\underset{#1}{\\operatorname{minimize}}}", 1],
    "maximize": ["{\\underset{#1}{\\operatorname{maximize}}}", 1],
    "argmin": "{\\mathop{\\mathrm{arg\\,min}}}",
    "argmax": "{\\mathop{\\mathrm{arg\\,max}}}",
    "orth": "{\\operatorname{orth}}",
    "ow": "{\\mathrm{otherwise}}",
    "iid": "{\\mathrm{i.i.d.}}",
    "wass": "{\\mathrm{W}}",
    "TV": "{\\mathrm{TV}}",
    "as": "{\\mathrm{a.s.}}",
    "whp": "{\\mathrm{w.h.p.}}",
    "simiid": "{\\sim_{\\iid}}",
    "ltsim": "{\\lesssim}",
    "gtsim": "{\\gtrsim}",
    "ltsimwhp": "{\\underset{\\whp}{\\lesssim}}",
    "gtsimwhp": "{\\underset{\\whp}{\\gtrsim}}",
    "psdgeq": "{\\succcurlyeq}",
    "psdleq": "{\\preccurlyeq}",
    "defn": "{\\overset{\\text{def}}{=}}",
    "normsubdiff": ["{\\partial\\norm{}_{#1}}", 1],
    "normalize": ["{\\frac{#1}{\\norm*{#1}_2}}", 1],
    "normalizeabs": ["{\\frac{#1}{\\abs*{#1}}}", 1],
    "iter": ["{#1^{(#2)}}", 2],
    "prox": ["{\\operatorname{prox}}_{#1}", 1],

    // Vector operators
    "tr": "{\\operatorname{tr}}",
    "diag": "{\\operatorname{diag}}",
    "Diag": "{\\operatorname{Diag}}",
    "vect": "{\\operatorname{vec}}",
    "vec": "{\\operatorname{vec}}",
    "Sym": "{\\operatorname{sym}}",
    "Symm": "{\\operatorname{sym}}",
    "Skew": "{\\operatorname{skew}}",
    "rank": "{\\operatorname{rank}}",
    "krank": "{\\operatorname{krank}}",
    "sign": "{\\operatorname{sign}}",
    "sgn": "{\\operatorname{sgn}}",
    "supp": "{\\operatorname{supp}}",
    "esssup": "{\\mathop{\\operatorname{ess\\,sup}}}",
    "vol": "{\\operatorname{vol}}",
    "Vol": "{\\operatorname{Vol}}",
    "tp": "{^{\\mathrm{T}}}",
    "adj": "{^{\\ast}}",
    "inv": "{^{-1}}",
    "One": "{\\mathbf{1}}",
    "Zero": "{\\mathbf{0}}",
    "Id": "{\\operatorname{\\mathrm{Id}}}",
    "conv": "{\\mathbin{\\ast}}",
    "iconv": "{\\mathbin{\\square}}",
    "xcorr": "{\\mathbin{\\star}}",
    "cconv": "{\\mathbin{\\circledast}}",
    "frob": "{\\mathrm{F}}",
    "HS": "{\\mathrm{HS}}",

    // Trig stuff
    "acos": "{\\operatorname{\\cos\\inv}}",
    "asin": "{\\operatorname{\\sin\\inv}}",
    "atan": "{\\operatorname{\\tan\\inv}}",
    "sech": "{\\operatorname{sech}}",
    "csch": "{\\operatorname{csch}}",

    // Calculus/geometry operators
    "Hess": "{\\operatorname{Hess}}",
    "grad": "{\\operatorname{grad}}",
    "Div": "{\\operatorname{div}}",
    "curl": "{\\operatorname{curl}}",
    "downto": "{\\searrow}",
    "upto": "{\\nearrow}",

    // CS operators
    "polylog": "{\\operatorname{polylog}}",
    "poly": "{\\operatorname{poly}}",

    // Stats operators
    "Ind": ["{\\mathds{1}}_{#1}", 1],
    "stddev": "{\\operatorname{stddev}}",
    "Unif": ["{\\operatorname{Unif}(#1)}", 1],
    "Bern": ["{\\operatorname{Bern}(#1)}", 1],
    "Pois": ["{\\operatorname{Pois}(#1)}", 1],
    "Binom": ["{\\operatorname{Binom}(#1, #2)}", 2],
    "Exp": "{\\operatorname{Exp}}",
    "BG": "{\\operatorname{BG}}",
    "Law": "{\\mathrm{Law}}",
    "indep": "{\\protect\\mathpalette{\\protect\\independenT}{\\perp}}",
    "independenT": ["{\\mathrel{\\rlap{$#1#2$}\\mkern2mu{#1#2}}}", 2],

    // Topology / set operators
    "compl": "{\\mathsf{c}}",
    "bd": "{\\operatorname{bd}}",
    "relbd": "{\\operatorname{relbd}}",
    "cl": "{\\operatorname{cl}}",
    "Conv": "{\\operatorname{conv}}",
    "dom": "{\\operatorname{dom}}",
    "epi": "{\\operatorname{epi}}",
    "aff": "{\\operatorname{aff}}",
    "cone": "{\\operatorname{cone}}",
    "ri": "{\\operatorname{ri}}",
    "im": "{\\operatorname{im}}",
    "Hom": "{\\operatorname{Hom}}",
    "End": "{\\operatorname{End}}",
    "Aut": "{\\operatorname{Aut}}",
    "Null": "{\\operatorname{null}}",
    "Span": "{\\operatorname{span}}",
    "row": "{\\operatorname{row}}",
    "col": "{\\operatorname{col}}",
    "range": "{\\operatorname{range}}",
    "Ran": "{\\operatorname{ran}}",
    "diam": "{\\operatorname{diam}}",
    "len": "{\\operatorname{len}}",
    "dist": "{\\operatorname{dist}}",
    "nnz": "{\\operatorname{nnz}}",
    "RE": "{\\operatorname{RE}}",
    "err": "{\\operatorname{err}}",
    "circulant": "{\\operatorname{circ}}",
    "tre": "{\\operatorname{tre}}",
    "etr": "{\\operatorname{etr}}",
    "proj": ["{\\operatorname{proj}_{#1}}", 1]
  };

  const delimitersToDefine = [
    // Simple paired delimiters
    "\\DeclarePairedDelimitersX{\\abs[1]}{\\lvert}{\\rvert}{ \ifblank{#1}{\:\cdot\:}{#1} }",
  ];

  const all_macros = { ...macros, ...additionalMacros };

  window.MathJax = {
    loader: {
      load: ['[tex]/boldsymbol', '[tex]/mathtools', '[tex]/ams', '[tex]/color']
    },
    tex: {
      packages: {'[+]': ['boldsymbol', 'mathtools', 'ams', 'color']},
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      tags: 'ams',
      macros: all_macros,
      mathtools: {
        pairedDelimiters: {
          // General pairing commands
          abs: ['\\lvert', '\\rvert', '{#1}', 1, '', ''],
          norm: ['\\lVert', '\\rVert', '{#1}', 1, '', ''],
          nnorm: ['\\vert\\kern-0.25ex\\vert\\kern-0.25ex\\vert', '\\vert\\kern-0.25ex\\vert\\kern-0.25ex\\vert', '{#1}', 1, '', ''],
          ip: ['\\langle', '\\rangle', '{#1}, {#2}', 2, '', ''],
          iip: ['\\llangle', '\\rrangle', '{#1}, {#2}', 2, '', ''],
          ceil: ['\\lceil', '\\rceil', '{#1}', 1, '', ''],
          floor: ['\\lfloor', '\\rfloor', '{#1}', 1, '', ''],
          KL: ['(', ')', '{#1} \\:\\|\\: {#2}', 2, '\\mathop{\\mathrm{KL}}', ''],

          // Set type commands
          set: ['\\{', '\\}', '{#1}', 1, '', ''],
          Pr: ['[', ']', '{#1}', 1, '\\mathbb{P}', ''],
          Prsub: ['[', ']', '{#2}', 2, '\\mathop{\\mathbb{P}}_{#1}', ''],
          E: ['[', ']', '{#1}', 1, '\\mathbb{E}', ''],
          Esub: ['[', ']', '{#2}', 2, '\\mathop{\\mathbb{E}}_{#1}', ''],
          Var: ['[', ']', '{#1}', 1, '\\mathrm{Var}', ''],
          cov: ['[', ']', '{#1}', 1, '\\mathrm{cov}', ''],
          Ent: ['[', ']', '{#2}', 2, '\\mathop{\\mathrm{Ent}}_{#1}', '']
        }
      }
    }
  };
</script>
<!-- <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script> -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>



<link
  href="https://fonts.googleapis.com"
  rel="preconnect"
  />
<link
  href="https://fonts.gstatic.com"
  rel="preconnect"
  crossorigin="anonymous"
  />
<script
  src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"
  type="text/javascript"
  ></script>
<script type="text/javascript">
  WebFont.load({
    google: {
      families: [
        "Lato:300,300italic,400,400italic,700,700italic",
        "Open Sans:300,300italic,400,400italic,700,700italic",
      ],
    },
  });
</script>


  <link rel="dns-prefetch" href="https://fonts.gstatic.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,700;1,400&amp;display=swap" rel="stylesheet">

  

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Sam D. Buchanan</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/">Home</a>
      
        
        <a class="page-link" href="/publications/">Publications</a>
      
        
        <a class="page-link" href="/blog/">Blog</a>
      
        
        <a class="page-link" href="/misc/">Misc.</a>
      
        
        <a class="page-link" href="/assets/cv.pdf">CV</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Past Updates</h1>
  </header>

  <div class="post-content">
    <ul>
  <li>
    <p><strong>2nd Conference on Parsimony and Learning:</strong> I co-organized the second
<a href="https://2025.cpal.cc">Conference on Parsimony and Learning (CPAL)</a>. Thanks to all
attendees for making it a success! <em>(Mar 2025)</em></p>
  </li>
  <li>
    <p><strong>Talk:</strong> Spoke at the <a href="https://www.ideal-institute.org/2024/09/04/workshop-on-harmonious-human-ai-ecosystems-2/">IDEAL Privacy and Interpretability in Generative
AI</a>
workshop. <em>(Nov 2024)</em></p>
  </li>
  <li>
    <p><strong>Talk:</strong> Spoke at <a href="https://cmsworkshops.com/Asilomar2024/view_session.php?SessionID=1086">Asilomar
2024</a>.
<em>(Oct 2024)</em></p>
  </li>
  <li>
    <p><strong>MDS ‘24 Special Session:</strong> Co-organizing a SIAM MDS ‘24 special session
on <a href="https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=80543">Mathematical Principles in Foundation
Models</a>.
<em>(Oct 2024)</em></p>
  </li>
  <li>
    <p><strong>Publication:</strong> The full version of <a href="http://arxiv.org/abs/2311.13110">the CRATE
story</a> has been accepted for publication in
JMLR.
<a href="https://ma-lab-berkeley.github.io/CRATE/">CRATE</a> is a “white-box” (yet
scalable) <em>transformer architecture</em> where each layer is derived from the
principles of compression and sparsification of the input data distribution.
This white-box derivation leads CRATE’s representations to have surprising
<a href="https://arxiv.org/abs/2308.16271">emergent segmentation properties</a> in
vision applications without any complex self-supervised pretraining. <em>(Aug 2024)</em></p>
  </li>
  <li>
    <p><strong>Talk:</strong> Spoke at the BIRS Oaxaca <a href="https://www.birs.ca/events/2024/5-day-workshops/24w5297">“Mathematics of Deep Learning”
workshop</a> about
white-box networks (Jun 2024).</p>
  </li>
  <li>
    <p><strong>White-Box Deep Networks Tutorials:</strong> We delivered a tutorial on building white-box deep neural networks
at <a href="https://cmsworkshops.com/ICASSP2024/tutorials.php#tut25">ICASSP 2024</a> in
Seoul (Apr 2024), and at <a href="https://cvpr2024-tutorial-low-dim-models.github.io">CVPR
2024</a> in Seattle (Jun
2024). The most recent tutorial slides can be found
<a href="https://www.dropbox.com/home/CVPR-tutorial">here</a> (Lectures 2-1 – 2-3).</p>
  </li>
  <li>
    <p><strong>Publication:</strong> <a href="https://zhenghanfang.github.io/learned-proximal-networks/">Learned proximal networks</a>, a methodology for
parameterizing, learning, and evaluating expressive priors for data-driven inverse
problem solvers with convergence guarantees, appeared in ICLR 2024.
The camera-ready version of the manuscript can be found
<a href="https://openreview.net/forum?id=kNPcOaqC5r">here</a>. <em>(May 2024)</em></p>
  </li>
  <li>
    <p><strong>Publication:</strong> <a href="https://ma-lab-berkeley.github.io/CRATE/">CRATE-MAE</a> appeared in ICLR 2024. At the heart of this work is a connection between
denoising and compression, which we use to derive a corresponding decoder
architecture for the “white-box” transformer CRATE encoder.
The camera-ready version of the manuscript can be found
<a href="https://openreview.net/forum?id=PvyOYleymy">here</a>. <em>(May 2024)</em>
<!-- This work is described in Section 3 of the [complete CRATE -->
<!-- paper](https://arxiv.org/abs/2311.13110). _(Jan 2024)_ --></p>
  </li>
  <li>
    <p><strong>Talk:</strong> Gave my annual Research at TTIC talk about <a href="https://brentyi.github.io/tilted">TILTED</a>! <a href="https://uchicago.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=db5b4c2a-96aa-4722-bb5f-b067015c0314">Here is the
video
recording</a>. <em>(Mar 2024)</em></p>
  </li>
  <li>
    <p><strong>Talk:</strong> Gave the <a href="https://redwood.berkeley.edu/seminars/sam-buchanan-feb-2024/">Redwood
Seminar</a>. <em>(Feb 2024)</em></p>
  </li>
  <li>
    <p><strong>Publication:</strong> We presented <a href="https://ma-lab-berkeley.github.io/CRATE/">CRATE</a> at <a href="https://neurips.cc/virtual/2023/poster/71567">NeurIPS
2023</a>, and as an oral in the
<a href="https://neurips.cc/virtual/2023/75163">XAI in Action</a> workshop. <em>(Dec 2023)</em></p>
  </li>
  <li>
    <p><strong>Publication:</strong> We presented <a href="https://brentyi.github.io/tilted/">TILTED</a> at
ICCV 2023. TILTED improves visual quality, compactness, and interpretability
for hybrid neural field 3D representations by incorporating geometry into the
latent features. Find the full version <a href="https://arxiv.org/abs/2308.15461">on arXiv</a>. <em>(Oct 2023)</em></p>
  </li>
  <li>
    <p><strong>ICLR 2024</strong>: Presented two posters in Vienna: <em>Learned Proximal Networks</em>
(Friday, May 10, a.m. session; <a href="https://zhenghanfang.github.io/learned-proximal-networks/">project
page</a>, <a href="https://iclr.cc/virtual/2024/poster/17978">ICLR
page</a>) and <em>CRATE-MAE</em> (Thursday,
May 9, a.m. session; <a href="https://ma-lab-berkeley.github.io/CRATE/">project
page</a>, <a href="https://iclr.cc/virtual/2024/poster/18688">ICLR
page</a>). <em>(May 2024)</em></p>
  </li>
  <li>
    <p><strong>1st Conference on Parsimony and Learning:</strong> I co-organized the inaugural <a href="https://2024.cpal.cc">Conference on
Parsimony and Learning (CPAL)</a>, which took place at the
University of Hong Kong from January 3–6, 2024. Thanks to all authors,
speakers, organizers, and especially to the local team at HKU, whose hard
work made the conference a success! Stay tuned for CPAL 2025. <em>(Jan 2024)</em></p>
  </li>
  <li>
    <p>(December 2023) <a href="https://arxiv.org/abs/2310.14344">New preprint posted</a> on
methodology for data-driven inverse problem solvers with convergence
guarantees. We presented this work at the <a href="https://neurips.cc/virtual/2023/79286">NeurIPS 2023 Learning-Based
Solutions for Inverse Problems</a>
workshop.</p>
  </li>
  <li>
    <p>(June 2023) We taught a short course at ICASSP 2023 in Rhodes, Greece, titled
<a href="https://highdimdata-lowdimmodels-tutorial.github.io/">“Learning Nonlinear and Deep Low-Dimensional Representations from High-Dimensional Data: From Theory to Practice”</a>.</p>
  </li>
  <li>
    <p>(January 2023) I co-organized the third <a href="https://slowdnn-workshop.github.io/">Workshop on Seeking
Low-Dimensionality in Deep Neural Networks
(SLowDNN)</a>. <a href="https://www.youtube.com/watch?v=EO39D_Jfq_E&amp;t=3s&amp;pp=ygUMc2FtIGJ1Y2hhbmFu">Here is a link to my
tutorial</a>.</p>
  </li>
  <li>
    <p>(September 2022) I defended my Ph.D. thesis (back in June!), and started as a
Research Assistant Professor at TTIC.</p>
  </li>
  <li>
    <p>(May 2022) I received the <a href="https://www.ee.columbia.edu/student-awards-and-fellowships">Eli Jury
Award</a> from the
Columbia EE Department for “outstanding achievement in the area of signal
processing”.</p>
  </li>
  <li>
    <p>(May 2022) We taught a short course at ICASSP 2022 in May, titled
<a href="https://highdimdata-lowdimmodels-tutorial.github.io/2022" target="_blank">“Low-Dimensional Models for High-Dimensional Data: From Linear to Nonlinear,
Convex to Nonconvex, and Shallow to
Deep”</a><!-- __ -->.
Slides are available!</p>
  </li>
  <li>
    <p>(April 2022) I attended the <a href="https://mlschool.princeton.edu/">Princeton ML Theory Summer
School</a> this summer from June 13–17.</p>
  </li>
  <li>
    <p>(March 2022) <a href="/assets/pdf/refine.pdf" target="_blank">New preprint released</a><!-- __ -->
on invariance-by-design neural architectures for computing with visual data,
with theoretical guarantees.  Feedback is very much appreciated!</p>
  </li>
  <li>
    <p>(December 2021) We presented our paper <a href="https://papers.nips.cc/paper/2021/hash/f26df67e8110ee2b44923db775e3e47f-Abstract.html" target="_blank">Deep Networks Provably Classify Data
on
Curves</a><!-- __ -->
at NeurIPS.</p>
  </li>
  <li>
    <p>(August 2021) I gave a <a href="https://www.youtube.com/watch?v=PEaYY2TLvYY" target="_blank">talk about our work on the multiple manifold
problem</a><!-- __ -->
at the IMA Workshop on Mathematical Foundation and Applications of Deep
Learning at Purdue. Thanks to the organizers for the opportunity to speak!</p>
  </li>
  <li>
    <p>(July 2021) I will be attending the <a href="https://deep-learning-summer-school.princeton.edu" target="_blank">Princeton Deep Learning Theory Summer
School</a><!-- __ --> this year.</p>
  </li>
  <li>
    <p>(May 2021) We will present our paper “Deep Networks and the Multiple Manifold
Problem” at ICLR 2021 on Thursday, May 6th! Conference link
<a href="https://iclr.cc/virtual/2021/poster/2530" target="_blank">here</a><!-- __ -->, paper
link <a href="https://openreview.net/forum?id=O-6Pm_d_Q-" target="_blank">here</a><!-- __ -->.</p>
  </li>
</ul>

  </div>

  

</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      


<div id="icon-container">
  <div>
    <a href=mailto:sam@ttic.edu style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/gmail.svg" alt="Mail icon" />
    </a>
  </div>
  <div>
    <a href=https://scholar.google.com/citations?user=5WT38A0AAAAJ style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/scholar.svg" alt="Google Scholar icon" />
    </a>
  </div>

  <div>
    <a href=https://twitter.com/_sdbuchanan
       style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/twitter.svg" alt="Twitter icon" />
    </a>
  </div>

  <div>
    <a href=https://www.linkedin.com/in/sam-buchanan-4507a6b3
       style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/linkedin.svg" alt="LinkedIn icon" />
    </a>
  </div>

  <div>
    <a href=https://github.com/sdbuch
       style="text-decoration: none">
      <img id="icon-container-item" src="/assets/icons/github.svg" alt="GitHub icon" />
    </a>
  </div>
</div>

    </p>

  </div>

</footer>


  </body>

  <!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Littlefoot for footnotes and citations -->
<script src="https://cdn.jsdelivr.net/npm/littlefoot@4/dist/littlefoot.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/littlefoot@4/dist/littlefoot.css">

<script>
document.addEventListener('DOMContentLoaded', function() {
  // Initialize Littlefoot for standard footnotes
  littlefoot.littlefoot({
    buttonTemplate: '<button aria-expanded="false" class="littlefoot__button" id="<% id %>" title="See Footnote"><% number %></button>',
    activateDelay: 100,
    activateCallback: function(popover, button) {
      // Render MathJax in the footnote popup
      if (window.MathJax && window.MathJax.typesetPromise) {
        window.MathJax.typesetPromise([popover]).catch(function (err) {
          console.log('MathJax typeset failed: ' + err.message);
        });
      }
    },
    allowMultiple: true,
    dismissDelay: 500,
    hoverDelay: 250,
    numberResetSelector: 'article',
    scope: 'body'
  });

  // Custom handler for jekyll-scholar citations
  const citeLinks = document.querySelectorAll('a[href*="#"]');
  citeLinks.forEach(function(link) {
    // Check if this is a citation link (points to bibliography)
    const href = link.getAttribute('href');
    if (href && href.startsWith('#') && href.match(/^#[A-Za-z]/)) {
      const targetId = href.substring(1);
      const targetElement = document.getElementById(targetId);
      
      // If target exists and looks like a bibliography entry
      if (targetElement && (targetElement.closest('.bibliography') || targetElement.tagName === 'LI')) {
        link.addEventListener('mouseenter', function(e) {
          showCitationPopup(e, targetElement);
        });
        
        link.addEventListener('mouseleave', function() {
          hideCitationPopup();
        });
        
        // Prevent default click behavior for hover-only interaction
        link.addEventListener('click', function(e) {
          e.preventDefault();
        });
      }
    }
  });
});

let citationPopup = null;
let hideTimeout = null;
let showTimeout = null;

function showCitationPopup(event, targetElement) {
  // Clear any pending show/hide operations
  if (hideTimeout) {
    clearTimeout(hideTimeout);
    hideTimeout = null;
  }
  if (showTimeout) {
    clearTimeout(showTimeout);
    showTimeout = null;
  }
  
  // Immediately hide any existing popup
  if (citationPopup && citationPopup.parentNode) {
    citationPopup.parentNode.removeChild(citationPopup);
    citationPopup = null;
  }
  
  // Show new popup after a short delay to prevent flicker
  showTimeout = setTimeout(function() {
    // Create popup
    citationPopup = document.createElement('div');
    citationPopup.className = 'littlefoot__popover citation-popup';
    citationPopup.innerHTML = '<div class="littlefoot__content citation-content">' + targetElement.innerHTML + '</div>';
    
    // Position popup
    const rect = event.target.getBoundingClientRect();
    citationPopup.style.position = 'absolute';
    citationPopup.style.top = (rect.bottom + window.scrollY + 5) + 'px';
    citationPopup.style.left = rect.left + 'px';
    citationPopup.style.zIndex = '1000';
    citationPopup.style.maxWidth = '400px';
    
    document.body.appendChild(citationPopup);
    
    // Render MathJax in the popup
    if (window.MathJax && window.MathJax.typesetPromise) {
      window.MathJax.typesetPromise([citationPopup]).catch(function (err) {
        console.log('MathJax typeset failed: ' + err.message);
      });
    }
    
    // Add hover handlers to keep popup open
    citationPopup.addEventListener('mouseenter', function() {
      if (hideTimeout) {
        clearTimeout(hideTimeout);
        hideTimeout = null;
      }
    });
    
    citationPopup.addEventListener('mouseleave', function() {
      hideCitationPopup();
    });
    
    showTimeout = null;
  }, 50);
}

function hideCitationPopup() {
  // Clear any pending show operation
  if (showTimeout) {
    clearTimeout(showTimeout);
    showTimeout = null;
  }
  
  // Clear any existing hide timeout
  if (hideTimeout) {
    clearTimeout(hideTimeout);
  }
  
  hideTimeout = setTimeout(function() {
    if (citationPopup && citationPopup.parentNode) {
      citationPopup.parentNode.removeChild(citationPopup);
      citationPopup = null;
    }
    hideTimeout = null;
  }, 100);
}
</script>


</html>
